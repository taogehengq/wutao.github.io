<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>视觉算法 | WT's Blog</title><meta name="author" content="WT"><meta name="copyright" content="WT"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="视觉算法1. CV子类CV 包含了图像分类、物体检测、图像分割、人脸识别、OCR（文字识别）、三维重建等众多子方向。 一、图像分类图像分类是 CV 最基础的任务，目标是给图像分配唯一的类别标签（如 “猫”“狗”“汽车”）。    类型 经典算法 &#x2F; 模型 核心特点 &amp; 适用场景    传统算法 1. HOG+SVM2. SIFT+BoW3. KNN &#x2F; 朴素贝叶斯 1.">
<meta property="og:type" content="article">
<meta property="og:title" content="视觉算法">
<meta property="og:url" content="https://taogehengq.github.io/2026/01/11/%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95/index.html">
<meta property="og:site_name" content="WT&#39;s Blog">
<meta property="og:description" content="视觉算法1. CV子类CV 包含了图像分类、物体检测、图像分割、人脸识别、OCR（文字识别）、三维重建等众多子方向。 一、图像分类图像分类是 CV 最基础的任务，目标是给图像分配唯一的类别标签（如 “猫”“狗”“汽车”）。    类型 经典算法 &#x2F; 模型 核心特点 &amp; 适用场景    传统算法 1. HOG+SVM2. SIFT+BoW3. KNN &#x2F; 朴素贝叶斯 1.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg2.png">
<meta property="article:published_time" content="2026-01-11T02:00:00.000Z">
<meta property="article:modified_time" content="2026-01-11T07:08:22.764Z">
<meta property="article:author" content="WT">
<meta property="article:tag" content="Hexo">
<meta property="article:tag" content="博客">
<meta property="article:tag" content="视觉算法">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg2.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "视觉算法",
  "url": "https://taogehengq.github.io/2026/01/11/%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95/",
  "image": "https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg2.png",
  "datePublished": "2026-01-11T02:00:00.000Z",
  "dateModified": "2026-01-11T07:08:22.764Z",
  "author": [
    {
      "@type": "Person",
      "name": "WT",
      "url": "https://taogehengq.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/wutao.github.io/img/favicon.png"><link rel="canonical" href="https://taogehengq.github.io/2026/01/11/%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/wutao.github.io/css/index.css?v=5.5.3"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/wutao.github.io/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '视觉算法',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div class="bg-animation" id="web_bg" style="background-image: url(https://s2.loli.net/2024/01/08/2NLQjw1oVCxdg4v.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/wutao.github.io/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/wutao.github.io/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/wutao.github.io/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/wutao.github.io/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/wutao.github.io/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/wutao.github.io/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/wutao.github.io/archives/"><i class="fa-fw fas fa-archives"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/wutao.github.io/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/wutao.github.io/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/wutao.github.io/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/wutao.github.io/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/wutao.github.io/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/wutao.github.io/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg2.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/wutao.github.io/"><span class="site-name">WT's Blog</span></a><a class="nav-page-title" href="/wutao.github.io/"><span class="site-name">视觉算法</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/wutao.github.io/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/wutao.github.io/archives/"><i class="fa-fw fas fa-archives"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/wutao.github.io/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/wutao.github.io/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/wutao.github.io/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/wutao.github.io/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/wutao.github.io/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/wutao.github.io/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">视觉算法</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2026-01-11T02:00:00.000Z" title="发表于 2026-01-11 10:00:00">2026-01-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-11T07:08:22.764Z" title="更新于 2026-01-11 15:08:22">2026-01-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/wutao.github.io/categories/%E6%8A%80%E6%9C%AF/">技术</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="视觉算法"><a href="#视觉算法" class="headerlink" title="视觉算法"></a>视觉算法</h1><h2 id="1-CV子类"><a href="#1-CV子类" class="headerlink" title="1. CV子类"></a>1. CV子类</h2><p>CV 包含了图像分类、物体检测、图像分割、人脸识别、OCR（文字识别）、三维重建等众多子方向。</p>
<h3 id="一、图像分类"><a href="#一、图像分类" class="headerlink" title="一、图像分类"></a>一、图像分类</h3><p>图像分类是 CV 最基础的任务，目标是给图像分配唯一的类别标签（如 “猫”“狗”“汽车”）。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>经典算法 &#x2F; 模型</th>
<th>核心特点 &amp; 适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>传统算法</td>
<td>1. HOG+SVM2. SIFT+BoW3. KNN &#x2F; 朴素贝叶斯</td>
<td>1. HOG+SVM：早期行人 &#x2F; 车辆分类；2. SIFT+BoW：基于特征词袋的通用分类；3. 简单场景，精度低</td>
</tr>
<tr>
<td>深度学习</td>
<td>1. LeNet-5（1998）2. AlexNet（2012）3. VGG-16&#x2F;19（2014）4. GoogLeNet（Inception）5. ResNet（2015）6. MobileNet（2017）7. ViT（2020）</td>
<td>1. LeNet：CNN 开山之作（手写数字识别）；2. AlexNet：ImageNet 夺冠，开启深度学习 CV 时代；3. VGG：规整卷积核设计，易迁移；4. GoogLeNet：多尺度特征融合；5. ResNet：残差网络，突破深度限制（可做 1000 层 +）；6. MobileNet：轻量化，适配手机 &#x2F; 边缘设备；7. ViT：Transformer 引入 CV，大模型时代标杆</td>
</tr>
</tbody></table>
<p><strong>代表框架</strong>：TorchVision、CLIP（零样本分类，视觉大模型）</p>
<h3 id="二、物体检测"><a href="#二、物体检测" class="headerlink" title="二、物体检测"></a>二、物体检测</h3><p>目标是识别图像中多个目标的<strong>位置（边界框）+ 类别</strong>，是 CV 落地最广的任务之一。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>经典算法 &#x2F; 模型</th>
<th>核心特点 &amp; 适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>传统算法</td>
<td>1. Haar+Adaboost（2001）2. HOG+SVM（2005）3. DPM（形变部件模型）</td>
<td>1. Haar+Adaboost：经典人脸检测（OpenCV 内置）；2. HOG+SVM：行人检测标杆；3. DPM：处理目标形变，精度提升但速度慢</td>
</tr>
<tr>
<td>深度学习</td>
<td>【两阶段（精度高）】1. R-CNN（2014）2. Fast R-CNN（2015）3. Faster R-CNN（2015）【单阶段（速度快）】4. YOLOv1-v9（2016-2024）5. SSD（2016）6. RetinaNet（2017）</td>
<td>1. R-CNN：深度学习检测开山，候选框 + 分类；2. Fast R-CNN：优化训练 &#x2F; 推理效率；3. Faster R-CNN：引入 RPN（区域提议网络），两阶段标杆（医疗 &#x2F; 高精度场景）；4. YOLO 系列：实时检测标杆（自动驾驶 &#x2F; 安防 &#x2F; 工业）；5. SSD：多尺度检测，平衡速度 + 精度；6. RetinaNet：解决类别不平衡，单阶段精度跃升</td>
</tr>
</tbody></table>
<p><strong>代表框架</strong>：MMDetection、Ultralytics YOLO（YOLO 官方）</p>
<p><strong>YOLO库</strong> 包含  实例分割 (Instance Segmentation)，姿态估计 (Pose Estimation)，旋转框检测 (OBB)，物体追踪 (Tracking)，图像分类，可基于同一框架快速切换。</p>
<h3 id="三、图像分割"><a href="#三、图像分割" class="headerlink" title="三、图像分割"></a>三、图像分割</h3><p>细分「语义分割（只分类别）、实例分割（分类别 + 个体）、全景分割（语义 + 实例）」，比检测更精细。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>经典算法 &#x2F; 模型</th>
<th>核心特点 &amp; 适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>传统算法</td>
<td>1. 阈值分割（OTSU）2. 边缘检测（Canny&#x2F;Sobel）3. 区域生长 &#x2F; 分水岭算法</td>
<td>1. 阈值分割：简单场景（如黑白文档）；2. 边缘检测：提取物体轮廓；3. 区域生长：基于像素相似性分割，医疗影像早期用</td>
</tr>
<tr>
<td>深度学习</td>
<td>【语义分割】1. FCN（2015）2. U-Net（2015）3. DeepLab v1-v3+（2014-2018）【实例分割】4. Mask R-CNN（2017）【全景分割】5. Panoptic FPN（2018）</td>
<td>1. FCN：分割领域开山，端到端像素分类；2. U-Net：医疗影像分割标杆（如肿瘤 &#x2F; 细胞分割）；3. DeepLab：引入空洞卷积 &#x2F; 注意力，语义分割精度标杆；4. Mask R-CNN：Faster R-CNN + 掩码分支，实例分割标杆；5. Panoptic FPN：全景分割开山，统一语义 + 实例</td>
</tr>
</tbody></table>
<p><strong>代表框架</strong>：MMSegmentation、SAM（Segment Anything，视觉大模型，零样本分割）</p>
<h3 id="四、人脸识别"><a href="#四、人脸识别" class="headerlink" title="四、人脸识别"></a>四、人脸识别</h3><table>
<thead>
<tr>
<th>类型</th>
<th>经典算法 &#x2F; 模型</th>
<th>核心特点 &amp; 适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>传统算法</td>
<td>1. 特征脸（Eigenface）2. Fisherface3. LBPH（局部二值模式）</td>
<td>1. Eigenface：PCA 降维提取人脸特征，早期人脸识别；2. Fisherface：LDA 降维，比 Eigenface 鲁棒；3. LBPH：抗光照变化，OpenCV 内置（门禁 &#x2F; 考勤）</td>
</tr>
<tr>
<td>深度学习</td>
<td>1. MTCNN（2016）2. FaceNet（2015）3. ArcFace（2019）4. InsightFace（开源框架）</td>
<td>1. MTCNN：人脸检测 + 对齐标杆（多尺度检测，手机解锁 &#x2F; 直播美颜）；2. FaceNet：Triplet Loss，人脸特征嵌入标杆；3. ArcFace：角度边际损失，工业级人脸识别标杆（准确率 99.8%+）；4. InsightFace：开源人脸算法库，覆盖检测 &#x2F; 识别全链路</td>
</tr>
</tbody></table>
<p><strong>代表框架</strong>：InsightFace、Face++（商汤）</p>
<h3 id="五、OCR（文字识别"><a href="#五、OCR（文字识别" class="headerlink" title="五、OCR（文字识别)"></a>五、OCR（文字识别)</h3><p>细分「文字检测（定位文字区域）、文字识别（识别字符）、端到端 OCR」，落地于票据 &#x2F; 车牌 &#x2F; 文档识别。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>经典算法 &#x2F; 模型</th>
<th>核心特点 &amp; 适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>传统算法</td>
<td>1. 投影法 &#x2F; 连通域分析2. 模板匹配3. OCRopus（早期开源）</td>
<td>1. 投影法：检测印刷体文字行；2. 模板匹配：固定字体 &#x2F; 场景（如数字识别）；3. 早期开源 OCR，精度低</td>
</tr>
<tr>
<td>深度学习</td>
<td>【文字检测】1. CTPN（2016）2. EAST（2017）3. DBnet（2019）【文字识别】4. CRNN+CTC Loss（2015）5. SAR（2018）【端到端】6. TrOCR（2021）7. YOLO-OCR</td>
<td>1. CTPN：检测竖排 &#x2F; 弯曲文字；2. EAST：实时文字检测，速度快；3. DBnet：工业级检测标杆（抗模糊 &#x2F; 形变）；4. CRNN：序列识别标杆（手写 &#x2F; 印刷体）；5. SAR：提升不规则文字识别精度；6. TrOCR：基于 Transformer，多模态 OCR（零样本）；7. YOLO-OCR：检测 + 识别一体化，部署简单</td>
</tr>
</tbody></table>
<p><strong>代表框架</strong>：PaddleOCR（百度，工业主流）、EasyOCR、Tesseract（传统 + 深度学习结合）</p>
<h3 id="六、三维重建"><a href="#六、三维重建" class="headerlink" title="六、三维重建"></a>六、三维重建</h3><table>
<thead>
<tr>
<th>类型</th>
<th>经典算法 &#x2F; 模型</th>
<th>核心特点 &amp; 适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>传统算法</td>
<td>1. 张正友标定法（2000）2. SfM（运动恢复结构）3. MVS（多视图立体匹配）4. PCL（点云库）</td>
<td>1. 张正友标定法：相机内参标定标杆；2. SfM：从多张无序图像重建 3D 点云（文物 &#x2F; 场景重建）；3. MVS：稠密点云重建；4. PCL：点云处理工具库（滤波 &#x2F; 配准）</td>
</tr>
<tr>
<td>深度学习</td>
<td>1. PointNet（2017）2. NeRF（2020）3. COLMAP（传统 + 深度学习）4. Pix2Point（图像转点云）</td>
<td>1. PointNet：点云处理开山，直接处理无序点云；2. NeRF：神经辐射场，照片级 3D 重建（元宇宙 &#x2F; 虚拟试穿）；3. COLMAP：SfM+MVS 工具，支持深度学习优化；4. Pix2Point：单图像生成 3D 点云（轻量化）</td>
</tr>
</tbody></table>
<p><strong>代表工具</strong>：COLMAP、Open3D、PyTorch3D</p>
<h3 id="各方向核心选型原则"><a href="#各方向核心选型原则" class="headerlink" title="各方向核心选型原则"></a>各方向核心选型原则</h3><ol>
<li><p>追求实时性（如安防 &#x2F; 自动驾驶）：优先单阶段检测（YOLO）、轻量化模型（MobileNet）；</p>
</li>
<li><p>追求高精度（如医疗 &#x2F; 工业质检）：优先两阶段检测（Faster R-CNN）、U-Net&#x2F;DeepLab；</p>
</li>
<li><p>边缘部署（如手机 &#x2F; 嵌入式）：优先 MobileNet、YOLOv8n、量化后的模型；</p>
</li>
<li><p>通用场景（零样本 &#x2F; 少样本）：优先视觉大模型（CLIP&#x2F;SAM&#x2F;TrOCR）。</p>
</li>
<li><p>图像分类</p>
</li>
</ol>
<table>
<thead>
<tr>
<th>选型</th>
<th>适用场景</th>
<th>落地案例</th>
</tr>
</thead>
<tbody><tr>
<td>✅ 优先选 YOLO-cls</td>
<td>1. 同一项目需同时做分类 + 检测 &#x2F; 分割（如 “先分类水果种类，再检测缺陷”）；2. 边缘设备实时分类（如产线水果分拣）；3. 想复用 YOLO 的部署链路（已适配 TensorRT&#x2F;ONNX）。</td>
<td>工厂产线苹果 &#x2F; 香蕉 &#x2F; 橙子实时分拣（树莓派部署，FPS≥15，Top-1 准确率≥98%）；自动驾驶场景分类（“行人 &#x2F; 车辆 &#x2F; 道路”，需和检测复用模型）。</td>
</tr>
<tr>
<td>❌ 优先选其他算法</td>
<td>1. 零样本 &#x2F; 少样本分类（无标注数据，如识别小众品类）→ CLIP；2. 追求极致分类精度（如 ImageNet 竞赛）→ TorchVision（ResNet&#x2F;ViT&#x2F;EfficientNet）；3. 纯轻量化分类（无多任务需求）→ MobileNet&#x2F;EfficientNet（TorchVision）；4. 跨模态分类（图文匹配）→ CLIP&#x2F;BLIP。</td>
<td>电商商品零样本分类（无标注，CLIP 直接匹配 “商品名称 + 图片”）；学术研究（自定义分类网络结构，基于 TorchVision 基础模块开发）；手机端纯分类（MobileNet INT8 量化，功耗更低）。</td>
</tr>
</tbody></table>
<ol start="2">
<li>物体检测（含普通 BBox &#x2F; 旋转框 OBB）</li>
</ol>
<table>
<thead>
<tr>
<th>选型</th>
<th>适用场景</th>
<th>落地案例</th>
</tr>
</thead>
<tbody><tr>
<td>✅ 优先选 YOLO（v8&#x2F;v9，含 OBB）</td>
<td>1. 实时检测（FPS≥15）：安防监控、自动驾驶感知、工业产线质检；2. 边缘部署（Jetson &#x2F; 手机）；3. 旋转框检测（航拍船只、斜排文字）；4. 小目标检测（YOLOv9 已优化，如工业微小缺陷）。</td>
<td>商场安防摄像头行人 &#x2F; 车辆实时检测（Jetson Orin 部署，FPS≥30，<a href="mailto:&#x6d;&#x41;&#80;&#64;&#48;&#x2e;&#x35;">mAP@0.5</a>≥90%）；航拍船只 OBB 检测（YOLOv8-OBB，角度误差≤5°）；手机壳微小划痕检测（YOLOv9，漏检率≤5%）。</td>
</tr>
<tr>
<td>❌ 优先选其他算法</td>
<td>1. 极致精度（低实时）：医疗影像肿瘤检测、遥感图像精细解译→ Faster R-CNN&#x2F;Mask R-CNN；2. 超小目标检测（如遥感图像车辆）→ RetinaNet&#x2F;ATSS（MMDetection）；3. 学术研究（复现两阶段算法、探索新结构）→ MMDetection 框架；4. 极低算力（比 YOLOn 更轻）→ SSD&#x2F;MobileNet-SSD。</td>
<td>医疗 CT 影像肺结节检测（Faster R-CNN，<a href="mailto:&#x6d;&#65;&#x50;&#x40;&#48;&#46;&#x35;">mAP@0.5</a>≥95%，接受 FPS&#x3D;2）；遥感图像超小目标检测（ATSS，小目标 mAP 提升 10%）；学术论文复现（基于 MMDetection 改 RPN 模块）。</td>
</tr>
</tbody></table>
<ol start="3">
<li>图像分割（实例 &#x2F; 语义 &#x2F; 全景）</li>
</ol>
<table>
<thead>
<tr>
<th>选型</th>
<th>适用场景</th>
<th>落地案例</th>
</tr>
</thead>
<tbody><tr>
<td>✅ 优先选 YOLO-seg</td>
<td>1. 实时实例分割：工业缺陷轮廓抠取、自动驾驶障碍物分割、直播背景分割；2. 边缘部署（Jetson Nano）；3. 同一项目需检测 + 分割（如 “检测缺陷 + 抠轮廓算面积”）。</td>
<td>工厂螺丝缺陷分割（Jetson Nano 部署，FPS≥10，Mask IoU≥85%）；自动驾驶车辆 &#x2F; 行人分割（YOLOv8-seg，实时感知）。</td>
</tr>
<tr>
<td>❌ 优先选其他算法</td>
<td>1. 高精度语义分割：医疗影像（肿瘤轮廓）→ U-Net&#x2F;U-Net++；2. 城市遥感分割→ DeepLabv3+&#x2F;PSPNet；3. 零样本分割（无标注）→ SAM（Segment Anything）；4. 全景分割（语义 + 实例）→ Panoptic FPN；5. 医学专用分割→ MedicalNet+U-Net。</td>
<td>肺癌 CT 影像肿瘤分割（U-Net++，Dice 系数≥90%）；城市遥感图像道路 &#x2F; 建筑分割（DeepLabv3+，IoU≥88%）；无标注的文物轮廓分割（SAM，零样本直接抠图）。</td>
</tr>
</tbody></table>
<ol start="4">
<li>人脸识别</li>
</ol>
<table>
<thead>
<tr>
<th>型</th>
<th>适用场景</th>
<th>落地案例</th>
</tr>
</thead>
<tbody><tr>
<td>❌ 不选 YOLO</td>
<td>所有人脸识别场景（YOLO 无人脸特征提取 &#x2F; 匹配模块，仅能检测人脸框，精度 &#x2F; 效率远低于专用算法）。</td>
<td>——</td>
</tr>
<tr>
<td>✅ 优先选其他算法</td>
<td>1. 人脸检测→ MTCNN&#x2F;RetinaFace；2. 人脸特征提取 &#x2F; 识别→ ArcFace&#x2F;InsightFace（工业主流）；3. 移动端人脸解锁→ InsightFace（轻量化版）；4. 大规模人脸检索→ Face++&#x2F;DeepFace。</td>
<td>小区门禁人脸识别（InsightFace，准确率≥99.8%）；手机人脸解锁（RetinaFace+ArcFace 轻量化版）。</td>
</tr>
</tbody></table>
<ol start="5">
<li>OCR（文字检测 + 识别）</li>
</ol>
<table>
<thead>
<tr>
<th>选型</th>
<th>适用场景</th>
<th>落地案例</th>
</tr>
</thead>
<tbody><tr>
<td>⚠️ 可选 YOLO-OCR</td>
<td>1. 简单场景（印刷体、正排文字、无弯曲 &#x2F; 模糊）；2. 同一项目需 OCR + 检测（如 “检测商品 + 识别商品码”）。</td>
<td>超市价签文字识别（正排印刷体，YOLO-OCR，识别率≥95%）；产线零件编号检测 + 识别（融合场景）。</td>
</tr>
<tr>
<td>✅ 优先选其他算法</td>
<td>1. 工业级 OCR（多语言、弯曲文字、低质图像、手写体）→ PaddleOCR&#x2F;EasyOCR；2. 文字检测→ DBnet&#x2F;EAST（比 YOLO 更适配文字形态）；3. 文字识别→ CRNN&#x2F;TrOCR（零样本手写体）；4. 端到端 OCR→ TrOCR（Transformer 版）。</td>
<td>票据手写文字识别（PaddleOCR，识别率≥90%）；车牌弯曲文字检测（DBnet，检测率≥98%）；多语言文档识别（EasyOCR，支持 100 + 语言）。</td>
</tr>
</tbody></table>
<ol start="6">
<li>三维重建</li>
</ol>
<table>
<thead>
<tr>
<th>❌ 不选 YOLO</th>
<th>所有三维重建场景（YOLO 是 2D 视觉算法，无 3D 点云 &#x2F; 重建能力）。</th>
<th>——</th>
</tr>
</thead>
<tbody><tr>
<td>✅ 优先选其他算法</td>
<td>1. 传统三维重建（多张图片→点云）→ COLMAP（SfM+MVS）；2. 深度学习重建→ NeRF（照片级 3D）&#x2F;PointNet（点云处理）；3. 点云处理→ PCL&#x2F;Open3D；4. 单目 3D 检测→ CenterPoint&#x2F;BEVFormer（自动驾驶）。</td>
<td>文物数字化重建（COLMAP，生成稠密点云）；元宇宙虚拟人重建（NeRF，照片级渲染）；自动驾驶 3D 感知（BEVFormer，感知车辆 3D 位置）。</td>
</tr>
</tbody></table>
<p>简单来说，<strong>YOLO 是 “工程落地神器”</strong>：实时、边缘、多任务、低成本，优先用于工业产线、安防、自动驾驶等落地场景；<strong>其他算法是 “专用 &#x2F; 高精度补充”</strong></p>
<ul>
<li>纯分类→ TorchVision&#x2F;CLIP；</li>
<li>高精度检测→ Faster R-CNN；</li>
<li>医学分割→ U-Net；</li>
<li>人脸→ InsightFace；</li>
<li>OCR→ PaddleOCR；</li>
<li>3D→ COLMAP&#x2F;NeRF；</li>
<li>零样本选大模型（CLIP&#x2F;SAM）</li>
</ul>
<h2 id="2-业务能力"><a href="#2-业务能力" class="headerlink" title="2. 业务能力"></a>2. 业务能力</h2><h3 id="岗位要求"><a href="#岗位要求" class="headerlink" title="岗位要求"></a>岗位要求</h3><p><strong>算法落地&#x2F;应用&#x2F;部署工程师（绝大多数）：</strong></p>
<ul>
<li><p><strong>核心要求：</strong> 能够灵活<strong>运用成熟技术</strong>解决业务问题。</p>
</li>
<li><p><strong>关键技能：</strong> Python&#x2F;C++ 熟练，懂模型转换，懂 CUDA 编程，懂 Docker，能把模型封装成 API。</p>
</li>
<li><p><strong>Level 1（基础）：</strong> 会下载 YOLO 代码，跑通 Demo，训练自己的数据集。</p>
</li>
<li><p><strong>Level 2（进阶 - 也是最实用的）：</strong> <strong>工程落地能力</strong>。</p>
<ul>
<li>怎么把模型转成 ONNX&#x2F;TensorRT 加速？</li>
<li>怎么在树莓派&#x2F;Jetson&#x2F;手机上跑得快？</li>
<li>怎么处理极度不平衡的数据？（比如工厂良品率99%，怎么训练识别那1%的次品？）</li>
</ul>
</li>
<li><p><strong>Level 3（融合）：</strong> 懂得如何将 LLM 与 CV 结合。</p>
<ul>
<li>例如：用 YOLO 检测出画面里有“人”和“车”，然后把这个信息喂给 LLM，让 LLM 判断“这个人是不是要偷车”。这是目前的**多模态（Multimodal）**趋势。</li>
</ul>
</li>
</ul>
<p><strong>举个例子</strong></p>
<ul>
<li><strong>场景：</strong> 工地安全帽检测。</li>
<li><strong>算法部分（20%）：</strong> 训练一个 YOLO 模型识别头和安全帽。</li>
<li><strong>业务逻辑部分（80%）：</strong><ul>
<li><strong>去重逻辑：</strong> 一个人在摄像头下走来走去，不能一直报警，需要写代码判断 ID 是否重复。</li>
<li><strong>区域逻辑：</strong> 只有进入“危险区域”不戴帽子才报警，休息区不戴不管。这需要写多边形判定代码。</li>
<li><strong>时间逻辑：</strong> 晚上没开工的时候不报警。</li>
<li><strong>容错逻辑：</strong> 摄像头突然黑屏了怎么办？模型误报把气球看成安全帽了怎么过滤？</li>
</ul>
</li>
</ul>
<h3 id="业务流程"><a href="#业务流程" class="headerlink" title="业务流程"></a>业务流程</h3><h4 id="第一部分：模型加速与转换-ONNX-TensorRT"><a href="#第一部分：模型加速与转换-ONNX-TensorRT" class="headerlink" title="第一部分：模型加速与转换 (ONNX&#x2F;TensorRT)"></a>第一部分：模型加速与转换 (ONNX&#x2F;TensorRT)</h4><p><strong>第一步：导出为 ONNX</strong></p>
<p><code>yolo export model=yolov8n.pt format=onnx opset=12</code></p>
<p><strong>第二步：转为 TensorRT (.engine)</strong></p>
<p><code>把 onnx 转成 engine，并开启 fp16 半精度加速（精度损失微乎其微，速度翻倍）</code></p>
<p><code>trtexec --onnx=yolov8n.onnx --saveEngine=yolov8n.engine --fp16</code></p>
<p><strong>第三步：推理代码编写</strong></p>
<p>到了这一步，不再用 PyTorch 库推理，而是用 tensorrt 的 Python 或 C++ API。需要自己写预处理（图片缩放、归一化）和后处理（NMS 非极大值抑制）。</p>
<h4 id="第二部分：在树莓派-Jetson-手机上跑得快"><a href="#第二部分：在树莓派-Jetson-手机上跑得快" class="headerlink" title="第二部分：在树莓派&#x2F;Jetson&#x2F;手机上跑得快"></a>第二部分：在树莓派&#x2F;Jetson&#x2F;手机上跑得快</h4><p><strong>1. 树莓派 (Raspberry Pi) —— CPU 为主</strong>  手机壳划痕检测</p>
<p>树莓派通常没有强大的 GPU。</p>
<ul>
<li><strong>核心策略：量化 (Quantization)。</strong><br>将模型参数从 FP32（32位浮点数，体积大计算慢）变成 INT8（8位整数）。精度下降一点点，速度提升巨大。</li>
<li><strong>推荐框架：</strong> <strong>TFLite</strong> (Google) 或 <strong>ONNX Runtime</strong>。</li>
<li><strong>操作：</strong> 导出时<strong>选择 int8 格式</strong>，或者使用 OpenVINO（如果你用 Intel 的计算棒）。</li>
</ul>
<p><strong>2. Jetson (Nano&#x2F;Orin) —— GPU 为主</strong>  螺丝缺陷检测<br>Jetson 是带显卡的嵌入式板子。</p>
<ul>
<li><strong>核心策略：</strong> <strong>必须用 TensorRT。</strong><br>在 Jetson 上直接跑 PyTorch 代码是极大的浪费。务必按照第一部分的步骤，转成 .engine 文件。</li>
<li><strong>进阶大杀器：DeepStream。</strong><br>NVIDIA 官方的一套 SDK。它能直接把“摄像头拉流 -&gt; 解码 -&gt; 预处理 -&gt; TensorRT推理 -&gt; 画框 -&gt; 编码推流”这一整套流程都在 GPU 内部完成，数据几乎不经过 CPU 拷贝，速度极快（能做到几十路视频同时分析）。</li>
</ul>
<p><strong>3. 手机 (Android&#x2F;iOS)</strong>  工厂巡检员用手机拍照检测次品</p>
<ul>
<li><strong>推荐框架：</strong> <strong>NCNN</strong> (腾讯开源，手机端最强之一) 或 <strong>MNN</strong> (阿里开源)。</li>
<li><strong>为什么？</strong> 它们针对手机的 ARM 架构做了汇编级的优化。</li>
<li><strong>操作：</strong><ol>
<li>pt -&gt; onnx -&gt; ncnn。</li>
<li>使用 Android Studio (C++ JNI) 调用 NCNN 库进行推理。</li>
</ol>
</li>
</ul>
<h4 id="第三部分：极度不平衡数据的处理-99-良品-vs-1-次品"><a href="#第三部分：极度不平衡数据的处理-99-良品-vs-1-次品" class="headerlink" title="第三部分：极度不平衡数据的处理 (99%良品 vs 1%次品)"></a>第三部分：极度不平衡数据的处理 (99%良品 vs 1%次品)</h4><p>方法一：数据层面的“暴力”平衡（Copy-Paste 大法）数据增强 &#x2F; 采样</p>
<p><strong>逻辑：</strong> 既然次品少，那我就人工造。</p>
<ul>
<li><strong>操作：</strong><ol>
<li>把那 1% 的次品图片找出来，用 Photoshop 或者代码把瑕疵部分（比如一个划痕）抠出来（扣掉背景）。</li>
<li>写脚本，把这个“划痕”随机粘贴到那 99% 的良品图片的不同位置上，并自动生成对应的标签文件（txt&#x2F;xml）。</li>
<li>甚至可以对划痕进行旋转、调暗、缩放。</li>
</ol>
</li>
<li><strong>效果：</strong> 强行把次品比例从 1:99 拉升到 1:1，让模型“看够”瑕疵。</li>
</ul>
<p>方法二：训练层面的“惩罚”（Focal Loss &#x2F; Weighted Loss）调损失函数 &#x2F; 难例挖掘</p>
<p><strong>逻辑：</strong> 考试的时候，简单的题（良品）做对了不加分，难的题（次品）做错了扣重分。</p>
<ul>
<li><strong>操作：</strong><br>在 YOLO 的损失函数配置中（通常在代码的 loss.py 部分），引入 <strong>Focal Loss</strong> 或增加正样本（次品）的权重。</li>
<li><strong>原理：</strong> Focal Loss 会降低简单样本（Easy Examples）的权重，强迫模型专注于那些难以分类的样本（Hard Examples）。</li>
</ul>
<p>方法三：思维转换 —— 无监督异常检测 (Anomaly Detection) 【最推荐的成熟方案】</p>
<p><strong>逻辑：</strong> 如果次品千奇百怪（划痕、黑点、变形、缺角），永远收集不完怎么办？<br><strong>那我们就不识别“次品”，我们只训练模型记住什么是“完美的良品”。</strong></p>
<ul>
<li><strong>技术路线：</strong> 不用 YOLO（物体检测），改用 <strong>Anomaly Detection（异常检测）</strong> 算法，如 <strong>Padim, PatchCore</strong>（可以使用 Anomalib 这个库）。</li>
<li><strong>流程：</strong><ol>
<li><strong>训练：</strong> 喂给模型 1000 张完美的良品图片。模型学会了良品的纹理分布。</li>
<li><strong>推理：</strong> 来了一张新图，模型会尝试用它学到的知识去“重建”这张图。</li>
<li><strong>判定：</strong> 如果图上有个黑点，模型重建不出来（因为它没学过黑点），重建误差就会很高。</li>
<li><strong>结果：</strong> 误差超过阈值 -&gt; 判定为次品，并高亮显示误差区域。</li>
</ol>
</li>
<li><strong>优势：</strong> <strong>不需要一张次品样本</strong>就能训练！非常适合工业场景。</li>
</ul>
<h3 id="难点总结"><a href="#难点总结" class="headerlink" title="难点总结"></a>难点总结</h3><p><strong>Q1：我们的业务要求实时性（30FPS），但你的 YOLO 目前在边缘设备（如 Jetson Nano）上只有 10FPS，你会从哪些角度去优化？</strong></p>
<ul>
<li><strong>初级回答：</strong> 换个小点的模型（比如 YOLOv8n），或者买更好的显卡。</li>
<li><strong>工程落地回答（满分）：</strong><br>我会采用<strong>由软到硬</strong>的分层优化策略：<ol>
<li><strong>输入端优化：</strong> 检查输入分辨率，是否必须 640x640？对于大物体检测，降采样到 320x320 速度能翻倍。</li>
<li><strong>模型转换：</strong> 放弃 PyTorch 原生推理，导出 ONNX，并使用 <strong>TensorRT</strong> 构建 Engine。</li>
<li><strong>精度量化：</strong> 使用 <strong>FP16</strong>（半精度）通常无损且速度提升 50%-100%。如果还不够，我会尝试 <strong>INT8 量化</strong>（需校准数据集），虽然有轻微掉点，但在嵌入式上能提速 3 倍以上。</li>
<li><strong>后处理加速：</strong> NMS（非极大值抑制）如果跑在 CPU 上是瓶颈，我会改写成 <strong>CUDA 实现的 Fast NMS</strong>，或者在导出 TensorRT 时直接把 NMS 算子以此 Plugin 的形式通过 End2End 方式打包装进模型里，减少 CPU-GPU 数据拷贝。</li>
</ol>
</li>
</ul>
<p><strong>Q2：多路视频流并发时，显存爆了或者 GPU 利用率忽高忽低怎么办？</strong></p>
<ul>
<li><strong>考察点：</strong> 显存管理、Batch 处理、流水线设计。</li>
<li><strong>关键点：</strong><ul>
<li><strong>Dynamic Batching（动态批处理）：</strong> 不要来一张图推一次。建立一个队列，凑够 4 张或 8 张图一起送进 GPU（Batch Size&#x3D;8），吞吐量会大幅提升。可以使用 NVIDIA <strong>Triton Inference Server</strong> 来自动管理。</li>
<li><strong>预处理&#x2F;解码瓶颈：</strong> 很多时候慢不是慢在模型，而是慢在 OpenCV 的 CPU 解码 (cv2.VideoCapture)。我会改用 <strong>GPU 硬解码</strong> (如 FFmpeg + NVDEC 或 DeepStream)，释放 CPU 资源。</li>
</ul>
</li>
</ul>
<p><strong>Q3：模型在训练集上表现很好（mAP 0.9），但在实际场景中经常误报（比如把反光的金属看成瑕疵），怎么解决？</strong></p>
<ul>
<li><strong>考察点：</strong> 泛化能力、Hard Sample Mining（难例挖掘）。</li>
<li><strong>工程落地回答：</strong><br>这说明训练数据分布和真实场景不一致。我不建议盲目调整模型结构，我会从数据侧入手：<ol>
<li><strong>难例挖掘 (Hard Negative Mining)：</strong> 部署代码中加入逻辑，把置信度在 0.3-0.6 之间模棱两可的图片，或者人工标记为误报的图片自动保存下来。</li>
<li><strong>专项微调：</strong> 把这些“反光金属”的图片加入负样本（Empty Images）进行重训，或者专门标注为“背景”。</li>
<li><strong>数据增强：</strong> 针对性增强。如果是反光问题，我在训练时会重点开启 <strong>HSV 变换、亮度抖动、随机遮挡</strong> 等增强策略，模拟各种光照条件。</li>
</ol>
</li>
</ul>
<p><strong>Q4：我们需要检测 4K 图片中的微小瑕疵（只有 10x10 像素），直接缩放到 640x640 检测不出来，怎么办？</strong></p>
<ul>
<li><strong>考察点：</strong> 小目标检测、切图逻辑。</li>
<li><strong>工程落地回答：</strong><br>直接缩放会导致小目标特征消失。我会使用 <strong>Slicing Aided Hyper Inference (SAHI)</strong> 类似的切图思路：<ol>
<li><strong>切图推理：</strong> 把 4K 图切成多个 640x640 的小图（带重叠区域 Overlap，防止物体被切断）。</li>
<li><strong>分别检测：</strong> 对每个小图进行预测。</li>
<li><strong>坐标还原与合并：</strong> 把小图的检测框坐标映射回 4K 大图坐标，并做全局 NMS 去重。</li>
<li><strong>弊端与权衡：</strong> 这会增加推理耗时，我会评估业务是否允许（例如增加到 200ms 延迟）。如果必须实时，我会考虑仅对“重点区域（ROI）”进行高分辨率裁剪检测。</li>
</ol>
</li>
</ul>
<p><strong>Q5：YOLO 检测出的框是抖动的（上一帧有，下一帧没，或者位置乱跳），导致业务统计不准，怎么处理？</strong></p>
<ul>
<li><strong>考察点：</strong> 追踪算法、平滑滤波、业务逻辑代码。</li>
<li><strong>工程落地回答：</strong><br>单帧检测必然存在抖动，必须引入<strong>时序信息</strong>：<ol>
<li><strong>引入追踪（Tracking）：</strong> 使用 ByteTrack 或 DeepSORT 给每个框分配 ID。如果 ID&#x3D;1 的物体连续 5 帧都出现，才算有效检测（由于迟滞效应，过滤闪烁）。</li>
<li><strong>卡尔曼滤波：</strong> 对框的中心点坐标做平滑预测，让框的移动看起来更丝滑。</li>
<li><strong>业务策略：</strong> 设置“进入&#x2F;离开缓冲区”。比如统计车流量，不是压线瞬间就计数，而是物体轨迹完全穿过区域后才计数。</li>
</ol>
</li>
</ul>
<p><strong>Q6：如果模型需要部署在 Docker 容器里，怎么尽可能减小镜像体积？</strong></p>
<ul>
<li><strong>考察点：</strong> 容器化、环境部署。</li>
<li><strong>关键点：</strong><ul>
<li>不要直接用 nvidia&#x2F;cuda:devel 这种几个 G 的基础镜像，用 runtime 或者 base 版本。</li>
<li>使用 <strong>Multi-stage build（多阶段构建）</strong>。</li>
<li>不要在生产环境装 PyTorch 完整版！只装 onnxruntime 或者只有 TensorRT 的运行库。PyTorch 动辄 1G+，而 ONNX Runtime 只有几十兆。</li>
</ul>
</li>
</ul>
<p><strong>Q7：你在这个项目中遇到的最大的困难是什么？你是怎么解决的？</strong></p>
<ul>
<li><strong>错误回答：</strong> “CUDA环境太难配了”、“数据标注太累了”。（这显得你很初级）</li>
<li><strong>加分回答（示例）：</strong><br>“最大的困难是<strong>推理延迟的不稳定性</strong>。<br>起初我们发现每隔几秒推理时间就会从 20ms 飙升到 100ms。经过 Nsight Systems 工具分析，发现是 Python 的垃圾回收（GC）机制导致的 CPU 阻塞，或者是 GPU 温度过高导致降频。<br><strong>解决：</strong> 我们最后重写了 C++ 推理模块，手动管理内存，并优化了散热策略&#x2F;锁定了 GPU 频率，最终将延迟方差控制在 2ms 以内。”</li>
</ul>
<p>关键词汇</p>
<ul>
<li><strong>吞吐量 (Throughput) &#x2F; 延迟 (Latency)</strong></li>
<li><strong>FP16 &#x2F; INT8 量化</strong></li>
<li><strong>TensorRT &#x2F; ONNX Runtime</strong></li>
<li><strong>难例挖掘 (Hard Sample Mining)</strong></li>
<li><strong>C++ 部署 &#x2F; 显存优化</strong></li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://taogehengq.github.io">WT</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://taogehengq.github.io/2026/01/11/%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95/">https://taogehengq.github.io/2026/01/11/视觉算法/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://taogehengq.github.io" target="_blank">WT's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/wutao.github.io/tags/Hexo/">Hexo</a><a class="post-meta__tags" href="/wutao.github.io/tags/%E5%8D%9A%E5%AE%A2/">博客</a><a class="post-meta__tags" href="/wutao.github.io/tags/%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95/">视觉算法</a></div><div class="post-share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg2.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/wutao.github.io/2026/01/11/%E5%A5%BD%E5%A5%BD%E9%94%BB%E7%82%BC/" title="好好锻炼"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg3.png" onerror="onerror=null;src='/wutao.github.io/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">好好锻炼</div></div><div class="info-2"><div class="info-item-1">好好锻炼一、力量训练：每周 3 次，每次 30-40 分钟（高效增肌 &#x2F; 塑形，提升代谢） 核心动作组合（全身覆盖，兼顾大肌群）： 下肢：深蹲（20 次 &#x2F; 组）、箭步蹲（左右各 10 次 &#x2F; 组）、臀桥（25 次 &#x2F; 组） 上肢：俯卧撑（跪姿 &#x2F; 标准，15 次 &#x2F; 组）、平板支撑（40 秒 &#x2F; 组）、俯身划船（可用矿泉水瓶当哑铃，12 次 &#x2F; 组） 核心：卷腹（20 次 &#x2F; 组）、俄罗斯转体（左右各 15 次 &#x2F; 组）安排：每个动作 3 组，组间休息 30 秒，全程 30 分钟搞定。   小器械加持（提升强度，可选）： 哑铃（1-3kg，女生）&#x2F;5-8kg（男生）：哑铃弯举、肩上推、侧平举（练肩背手臂） 弹力带：侧步走（练臀）、划船（练背）、手臂屈伸（练肱三头肌）优势：小器械易收纳，适合小户型，训练针对性更强。    二、有氧训练：每周 3 次，每次 20-30 分钟（燃脂 + 提升心肺）1. 高效燃脂型（适合时间紧张） HIIT（高强度间歇训练）： 动作：开合跳、高...</div></div></div></a><a class="pagination-related" href="/wutao.github.io/2026/01/11/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/" title="大模型开发学习路线"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="onerror=null;src='/wutao.github.io/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">大模型开发学习路线</div></div><div class="info-2"><div class="info-item-1">大模型开发学习路线一、岗位能力地图（你需要会到什么程度）  编程与工程 Python&#x2F;TypeScript，异步与并发，API 设计，单元&#x2F;集成测试，Docker，基础云原生（K8s&#x2F;Helm）。   LLM 基础与调用 token&#x2F;上下文&#x2F;温度&#x2F;采样，系统提示与模式约束（JSON schema）、函数&#x2F;工具调用，多模型路由与回退。   RAG 与检索 数据清洗与切块（chunk）、embedding 选型，混合检索（BM25+向量）、重排（rerank）、重复消解，召回评测。   微调与蒸馏 SFT&#x2F;LoRA&#x2F;QLoRA、指令数据构造、对齐（RLAIF&#x2F;RLHF 基本概念）、量化（INT8&#x2F;4）与部署兼容性。   评测与治理 黄金集构建、离线评测（检索&#x2F;回答&#x2F;安全）、线上反馈闭环、A&#x2F;B、可观测（日志&#x2F;追踪）、版本化与回滚。   推理与部署 vLLM&#x2F;TGI&#x2F;Ollama，连续批处理、KV cache、流式、超...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/wutao.github.io/2026/01/11/%E8%B4%A6%E5%8F%B7%E4%BF%A1%E6%81%AF/" title="账号密码"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-11</div><div class="info-item-2">账号密码</div></div><div class="info-2"><div class="info-item-1">一些账号  ak sk </div></div></div></a><a class="pagination-related" href="/wutao.github.io/2026/01/11/RAG/" title="RAG 入门"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg2.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-11</div><div class="info-item-2">RAG 入门</div></div><div class="info-2"><div class="info-item-1">RAG什么是RAG? RAG（Retrieval-Augmented Generation，检索增强生成）一种将“信息检索”与“生成式大模型”耦合的架构。系统先通过稠密向量或稀疏检索，从大规模外部知识库中定位与当前查询最相关的文档片段（context），再把这些片段连同原始查询一起送入大语言模型（LLM）作为 prompt 的上下文，让模型在生成回答时既利用内部参数知识，又利用最新的外部知识，从而显著降低幻觉、提升时效性与可溯源性。其典型流程：Indexing → Retrieval → Augmentation → Generation。一句话解释就是：先用“搜索引擎”找到相关文档，再让“作文高手”参考这些资料写答案，既新鲜又靠谱。 实现方式 1.1平台实现 fastgpt、coze、dify等 1.2代码实现 代码有哪些技术栈？  具体技术细节有哪些？  文档提取  1.1txt问本提取 1.2pdf提取工具  1.3表格提前工具 使用Llama Hub中的Database Reader工具连接MySQL数据库，并将数据库表数据加载到Llama Index的Documents...</div></div></div></a><a class="pagination-related" href="/wutao.github.io/2026/01/11/hexo%E5%85%A5%E9%97%A8/" title="Typora入门"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-11</div><div class="info-item-2">Typora入门</div></div><div class="info-2"><div class="info-item-1">Typora入门 文本格式设置： 加粗：在要加粗的文本前后各输入两个星号 “**”，或选中文字后按快捷键 Ctrl+B。 斜体：在要斜体的文本前后各输入一个星号 “*”，快捷键为 Ctrl+I。 粗斜体：在要设置的文本前后各输入三个星号 “***”。 高亮：在要高亮的文本前后各输入两个等号 “&#x3D;&#x3D;”，需在偏好设置的 Markdown 扩展语法内启用。 删除线：在要添加删除线的文本前后各输入两个波浪号 “~~”，快捷键为 Alt+Shift+5。 下划线：选中文字后按快捷键 Ctrl+U，或使用 HTML 标签文本。   标题设置： 输入 “#” 加空格，可创建一级标题，快捷键为 Ctrl+1。 输入 “##” 加空格，可创建二级标题，快捷键为 Ctrl+2，以此类推，最多支持六级标题。   列表创建： 无序列表：使用 “*”“-” 或 “+” 加空格都可以创建，快捷键为 Ctrl+Shift+L。 有序列表：使用 “1.”“2.”“3.” 加空格创建，快捷键为 Ctrl+Shift+O。 任务列表：语法为 “- ()”，减号后、括号内和括号后各有一个空格，括号...</div></div></div></a><a class="pagination-related" href="/wutao.github.io/2026/01/11/AI%20agent%20%E5%BC%80%E5%8F%91%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/" title="AI agent 开发知识总结"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg3.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-11</div><div class="info-item-2">AI agent 开发知识总结</div></div><div class="info-2"><div class="info-item-1">AI agent 开发知识总结什么是agent？ Agent（智能体 &#x2F; 自主代理）在 LLM 驱动的语境下，Agent 指以大规模语言模型为核心控制器（brain），配合记忆（memory）、工具调用（tool use）、规划（planning）与行动（action）模块，形成能够感知环境、制定计划并调用外部 API、函数或机器人执行多步任务，最终完成复杂目标的自治软件实体。它通常遵循观察（observe）→ 思考（reason）→ 行动（act）的循环，支持多轮对话、状态更新和任务拆解。一句话解释就是：给 AI 装上记忆、手脚和工具，让它像人一样自己思考、查资料、做任务，直到把事情办完。 本质上，所有的 Agent 设计模式都是将人类的思维、管理模式以结构化prompt的方式告诉大模型来进行规划，并调用工具执行，且不断迭代的方法,从这个角度来说，Agent设计模式很像传统意义上的程序开发范式，但是泛化和场景通用性远大于传统的程序开发范式。在Agent设计模式中，Prompt可以类比为Python这类高级编程语言，大模型可以类比于程序语言编译&amp;解释器。 任务规...</div></div></div></a><a class="pagination-related" href="/wutao.github.io/2026/01/11/%E4%BB%B7%E5%80%BC%E5%B1%95%E7%A4%BA/" title="价值展示"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg2.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-11</div><div class="info-item-2">价值展示</div></div><div class="info-2"><div class="info-item-1">价值展示 足够强大-领袖气质。 硬价值—-钱，颜值，身材，地位。价值越高，分数越高。钱可以装，不要寒酸气，颜值需要收拾，肌肉合适。软价值—-内在特质。幽默，领导力，光环效应，有主见。 无意识展示价值。 拉升关系。  吸引7步法 开场白–激发回复欲望，朋友圈，我的状态加感受，延续话题。 交换基本信息–只说半句，一句正经一句逗比。表演型人格 拉近距离–装b，有价值。侧面，让女生主动问。 形象塑造– 升温关系– 可得性– 邀约– 什么是黄毛？ 答案是有颜值有身材有物质条件有审美有学习力有方向感有执行力有原则有格局有边界有攻击性有主体性勇敢情绪稳定 </div></div></div></a><a class="pagination-related" href="/wutao.github.io/2026/01/11/Agent%20%E5%85%A8%E9%9D%A2%E6%8A%80%E8%83%BD/" title="Agent 全面技能"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-11</div><div class="info-item-2">Agent 全面技能</div></div><div class="info-2"><div class="info-item-1">Agent 全面技能（Level-2&#x2F;3）1. 语言与生态 Python 异步&#x2F;协程 FastAPI &#x2F; Flask Node.js + LangChain.js  2. 算法与微调 LoRA &#x2F; PEFT 微调 RLHF（强化学习对齐） 多模态（CLIP、Whisper）  3. 记忆系统 向量数据库（Milvus, Pinecone） 图数据库（Neo4j） 缓存（Redis 语义缓存）  4. Planning 策略 ReAct &#x2F; Reflexion &#x2F; Plan-and-Execute 多 Agent 协作（CrewAI、AutoGen） 状态机与工作流引擎  5. 工具与集成 Function Calling（OpenAI JSON Mode） MCP 协议（Model-Context-Protocol） API Gateway、OAuth、Webhook  6. 安全与合规 Prompt 注入防御 PII 脱敏、审计日志 RBAC 权限模型  7. 运维与评测 LLMOps（CI&#x2F;CD、A&#x2...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/wutao.github.io/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/wutao.github.io/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">WT</div><div class="author-info-description">记录学习路上的点点滴滴，记得好好生活哦</div><div class="site-data"><a href="/wutao.github.io/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/wutao.github.io/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/wutao.github.io/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/taogehengq"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95"><span class="toc-number">1.</span> <span class="toc-text">视觉算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-CV%E5%AD%90%E7%B1%BB"><span class="toc-number">1.1.</span> <span class="toc-text">1. CV子类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB"><span class="toc-number">1.1.1.</span> <span class="toc-text">一、图像分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B"><span class="toc-number">1.1.2.</span> <span class="toc-text">二、物体检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2"><span class="toc-number">1.1.3.</span> <span class="toc-text">三、图像分割</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB"><span class="toc-number">1.1.4.</span> <span class="toc-text">四、人脸识别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%94%E3%80%81OCR%EF%BC%88%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB"><span class="toc-number">1.1.5.</span> <span class="toc-text">五、OCR（文字识别)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA"><span class="toc-number">1.1.6.</span> <span class="toc-text">六、三维重建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%84%E6%96%B9%E5%90%91%E6%A0%B8%E5%BF%83%E9%80%89%E5%9E%8B%E5%8E%9F%E5%88%99"><span class="toc-number">1.1.7.</span> <span class="toc-text">各方向核心选型原则</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E4%B8%9A%E5%8A%A1%E8%83%BD%E5%8A%9B"><span class="toc-number">1.2.</span> <span class="toc-text">2. 业务能力</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B2%97%E4%BD%8D%E8%A6%81%E6%B1%82"><span class="toc-number">1.2.1.</span> <span class="toc-text">岗位要求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B"><span class="toc-number">1.2.2.</span> <span class="toc-text">业务流程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%EF%BC%9A%E6%A8%A1%E5%9E%8B%E5%8A%A0%E9%80%9F%E4%B8%8E%E8%BD%AC%E6%8D%A2-ONNX-TensorRT"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">第一部分：模型加速与转换 (ONNX&#x2F;TensorRT)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%EF%BC%9A%E5%9C%A8%E6%A0%91%E8%8E%93%E6%B4%BE-Jetson-%E6%89%8B%E6%9C%BA%E4%B8%8A%E8%B7%91%E5%BE%97%E5%BF%AB"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">第二部分：在树莓派&#x2F;Jetson&#x2F;手机上跑得快</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%EF%BC%9A%E6%9E%81%E5%BA%A6%E4%B8%8D%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86-99-%E8%89%AF%E5%93%81-vs-1-%E6%AC%A1%E5%93%81"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">第三部分：极度不平衡数据的处理 (99%良品 vs 1%次品)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%BE%E7%82%B9%E6%80%BB%E7%BB%93"><span class="toc-number">1.2.3.</span> <span class="toc-text">难点总结</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/wutao.github.io/2026/01/11/AI%20agent%20%E5%BC%80%E5%8F%91%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/" title="AI agent 开发知识总结"><img src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg3.png" onerror="this.onerror=null;this.src='/wutao.github.io/img/404.jpg'" alt="AI agent 开发知识总结"/></a><div class="content"><a class="title" href="/wutao.github.io/2026/01/11/AI%20agent%20%E5%BC%80%E5%8F%91%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/" title="AI agent 开发知识总结">AI agent 开发知识总结</a><time datetime="2026-01-11T02:00:00.000Z" title="发表于 2026-01-11 10:00:00">2026-01-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/wutao.github.io/2026/01/11/Agent%20%E5%85%A8%E9%9D%A2%E6%8A%80%E8%83%BD/" title="Agent 全面技能"><img src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="this.onerror=null;this.src='/wutao.github.io/img/404.jpg'" alt="Agent 全面技能"/></a><div class="content"><a class="title" href="/wutao.github.io/2026/01/11/Agent%20%E5%85%A8%E9%9D%A2%E6%8A%80%E8%83%BD/" title="Agent 全面技能">Agent 全面技能</a><time datetime="2026-01-11T02:00:00.000Z" title="发表于 2026-01-11 10:00:00">2026-01-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/wutao.github.io/2026/01/11/RAG%20%E5%AE%8C%E6%95%B4%E6%8A%80%E6%9C%AF%E6%A0%88/" title="RAG 完整技术栈"><img src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg2.png" onerror="this.onerror=null;this.src='/wutao.github.io/img/404.jpg'" alt="RAG 完整技术栈"/></a><div class="content"><a class="title" href="/wutao.github.io/2026/01/11/RAG%20%E5%AE%8C%E6%95%B4%E6%8A%80%E6%9C%AF%E6%A0%88/" title="RAG 完整技术栈">RAG 完整技术栈</a><time datetime="2026-01-11T02:00:00.000Z" title="发表于 2026-01-11 10:00:00">2026-01-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/wutao.github.io/2026/01/11/MY%20mind-%E8%AE%B0%E5%BD%95%E6%97%B6%E9%97%B4%E6%B5%81%E9%80%9D%E7%9A%84%E8%AE%B0%E5%BF%86/" title="MY mind-记录时间流逝的记忆"><img src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg3.png" onerror="this.onerror=null;this.src='/wutao.github.io/img/404.jpg'" alt="MY mind-记录时间流逝的记忆"/></a><div class="content"><a class="title" href="/wutao.github.io/2026/01/11/MY%20mind-%E8%AE%B0%E5%BD%95%E6%97%B6%E9%97%B4%E6%B5%81%E9%80%9D%E7%9A%84%E8%AE%B0%E5%BF%86/" title="MY mind-记录时间流逝的记忆">MY mind-记录时间流逝的记忆</a><time datetime="2026-01-11T02:00:00.000Z" title="发表于 2026-01-11 10:00:00">2026-01-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/wutao.github.io/2026/01/11/hexo%E5%85%A5%E9%97%A8/" title="Typora入门"><img src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="this.onerror=null;this.src='/wutao.github.io/img/404.jpg'" alt="Typora入门"/></a><div class="content"><a class="title" href="/wutao.github.io/2026/01/11/hexo%E5%85%A5%E9%97%A8/" title="Typora入门">Typora入门</a><time datetime="2026-01-11T02:00:00.000Z" title="发表于 2026-01-11 10:00:00">2026-01-11</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By WT</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/wutao.github.io/js/utils.js?v=5.5.3"></script><script src="/wutao.github.io/js/main.js?v=5.5.3"></script><div class="js-pjax"></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/fireworks.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>